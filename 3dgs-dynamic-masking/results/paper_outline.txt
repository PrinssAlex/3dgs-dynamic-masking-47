
===============================================================================
PROJECT PAPER OUTLINE
Title: 2D Semantic Masking for 3D Gaussian Splatting: Static Artifact Reduction
===============================================================================

1. ABSTRACT 
   - Problem: Dynamic objects degrade static background in 3DGS
   - Solution: Loss masking & ray filtering using 2D semantic masks
   - Results: Loss Masking significantly reduced static L1 error (e.g., from ~0.0037 to ~0.0026)
   - Contribution: Controlled ablation eliminating dynamic artifacts

2. INTRODUCTION 
   - Context: 3DGS for robot manipulation + environment reconstruction
   - Challenge: Robot motion contaminates static background (ghosting)
   - Motivation: Clean static maps for visual servoing/navigation
   - Thesis: Simple 2D masks eliminate dynamic artifacts

3. RELATED WORK 
   - 3D Gaussian Splatting [Kerbl et al., SIGGRAPH 2023]
   - Dynamic 3DGS extensions (4D-GS, transient removal)
   - Mask-guided NeRF methods
   - Semantic control in radiance fields

4. METHODOLOGY 
   4.1 Baseline 3DGS
      - Standard L1 loss, PyBullet views (256x144)
      - Initial 2000 Gaussians (from COLMAP), 30000 iterations, no densification

   4.2 Loss Masking
      - L_masked = mean(|rendered-GT| * static_mask)
      - Only static pixels contribute gradients

   4.3 Ray Filtering
      - Skip Gaussians projecting into dynamic mask regions
      - Rasterization-level intervention

5. EXPERIMENTS 
   5.1 PyBullet Dataset
      - Static plane/wall + rotating 3-joint robot arm
      - RGB images + binary masks + camera poses
      - Test on specific frames

   5.2 Training Protocol
      - Identical settings across all methods
      - Evaluation: PSNR↑, SSIM↑, LPIPS↓, Static L1↓

   5.3 Metrics
      - Static L1: Error on background pixels only
      - Full-frame PSNR/SSIM/LPIPS for overall quality

6. RESULTS 
   6.1 Quantitative Results (Example based on actual runs)
      | Method      | PSNR↑ | SSIM↑ | LPIPS↓ | Static L1↓ |
      |-------------|-------|-------|--------|------------|
      | Baseline    | ~25.24| ~0.923| ~0.172 | ~0.0037   |
      | Loss-Mask   | ~22.92| ~0.908| ~0.217 | ~0.0026   |
      | Ray-Filter  | ~20.61| ~0.863| ~0.193 | ~0.0100   |

   6.2 Key Findings
      - Loss-Mask: Significant reduction in static L1 error vs baseline
      - Ray-Filter: Did not improve static L1 error in this implementation
      - Loss-Mask excels on targeted static metric

   6.3 Qualitative
      - Side-by-side renders + error heatmaps

7. DISCUSSION 
   - Why it works: Removes dynamic-static gradient conflict
   - Loss-Mask shows promise for static reconstruction
   - Limitations: Synthetic data, perfect masks
   - Future: Real robot data, noisy masks, refine Ray Filtering

8. CONCLUSION 
   - Loss Masking strategy successfully improved static background reconstruction
   - Ray Filtering requires further development
   - Approach suitable for robotics applications

9. REFERENCES
   [1] Kerbl et al. (2023) 3D Gaussian Splatting, SIGGRAPH
   [2] Your implementation details

===============================================================================
ESTIMATED LENGTH: 12-15 pages (with figures/tables)
===============================================================================
